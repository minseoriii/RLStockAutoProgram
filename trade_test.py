import os
import pandas as pd
import numpy as np
import matplotlib
matplotlib.use('Agg') 
import matplotlib.pyplot as plt
from stable_baselines3 import PPO, A2C, DDPG, SAC
import gymnasium as gym
from gymnasium import spaces
from finrl.config import INDICATORS

# ë¼ì´ë¸ŒëŸ¬ë¦¬ ì¶©ëŒ ë°©ì§€
os.environ["KMP_DUPLICATE_LIB_OK"] = "TRUE"

# [Custom1MinEnv í´ëž˜ìŠ¤ ì •ì˜ - ì´ì „ê³¼ ë™ì¼]
class Custom1MinEnv(gym.Env):
    def __init__(self, df, stock_dim, hmax, initial_amount, buy_cost_pct, sell_cost_pct, reward_scaling, state_space, action_space, tech_indicator_list, **kwargs):
        self.df = df
        self.stock_dim = stock_dim
        self.hmax = hmax
        self.initial_amount = initial_amount
        self.buy_cost_pct = buy_cost_pct
        self.sell_cost_pct = sell_cost_pct
        self.reward_scaling = reward_scaling
        self.state_space = state_space
        self.action_space_dim = action_space
        self.tech_indicator_list = tech_indicator_list
        self.action_space = spaces.Box(low=-1, high=1, shape=(self.action_space_dim,))
        self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape=(self.state_space,))
        self.reset()

    def reset(self, seed=None, options=None):
        self.current_step = 0
        self.data = self.df.iloc[self.current_step, :]
        self.state = self._initiate_state()
        self.asset_memory = [self.initial_amount]
        self.terminal = False 
        return self.state, {}

    def _initiate_state(self):
        prices = [self.data.close]
        shares = [0]
        indic = [self.data[tech] for tech in self.tech_indicator_list]
        state = [self.initial_amount] + prices + shares + indic
        return np.array(state, dtype=np.float32)

    def step(self, actions):
        self.terminal = self.current_step >= len(self.df) - 1
        if self.terminal: return self.state, 0, self.terminal, False, {}
        price = self.data.close
        action = actions[0] * self.hmax
        cash, shares = self.state[0], self.state[2]
        if action > 0:
            buy_num = min(cash // (price * (1 + self.buy_cost_pct[0])), action)
            cash -= price * buy_num * (1 + self.buy_cost_pct[0]); shares += buy_num
        elif action < 0:
            sell_num = min(shares, abs(action))
            cash += price * sell_num * (1 - self.sell_cost_pct[0]); shares -= sell_num
        self.current_step += 1
        self.data = self.df.iloc[self.current_step, :]
        self.state = np.array([cash, price, shares] + [self.data[tech] for tech in self.tech_indicator_list], dtype=np.float32)
        total_asset = cash + shares * self.data.close
        self.asset_memory.append(total_asset)
        return self.state, 0, self.terminal, False, {}

# ==========================================
# ì‹¤í–‰ ì„¤ì •
# ==========================================
base_dir = r"C:\Stock_AI"
parquet_path = os.path.join(base_dir, "data_parquet", "0120G0.parquet")
model_dir = os.path.join(base_dir, "models_1min_test")
model_types = {'ppo': PPO, 'a2c': A2C, 'ddpg': DDPG, 'sac': SAC}

df = pd.read_parquet(parquet_path)
test_df = df.iloc[int(len(df)*0.8):].reset_index(drop=True)

# ë‹¤ë¥¸ ëª¨ë¸ë“¤ì´ ì›€ì§ì´ê²Œ í•˜ê¸° ìœ„í•´ ìˆ˜ìˆ˜ë£Œ 0, hmax 500ìœ¼ë¡œ ìƒí–¥ ì¡°ì •
env_kwargs = {
    "stock_dim": 1, "hmax": 500, "initial_amount": 10_000_000,
    "buy_cost_pct": [0.00], "sell_cost_pct": [0.00], "reward_scaling": 1e-4,
    "state_space": 13, "action_space": 1, 
    "tech_indicator_list": INDICATORS + ['hour', 'minute']
}

all_histories = {}
ensemble_actions = []

print("ðŸ“Š ëª¨ë¸ë³„ ìˆ˜ìµë¥  ë° í–‰ë™ ë¶„ì„ ì‹œìž‘...")

# 1. ëª¨ë¸ë³„ ê°œë³„ í…ŒìŠ¤íŠ¸ (í•™ìŠµ ì½”ë“œ ì‚­ì œí•˜ê³  'í…ŒìŠ¤íŠ¸'ë§Œ ì§„í–‰)
for name, model_class in model_types.items():
    model_path = os.path.join(model_dir, f"{name}_0120G0.zip")
    
    if os.path.exists(model_path):
        model = model_class.load(model_path)
        env = Custom1MinEnv(df=test_df, **env_kwargs)
        obs, _ = env.reset()
        done = False
        model_acts = []
        
        while not done:
            action, _ = model.predict(obs, deterministic=True)
            model_acts.append(action[0]) # ì•™ìƒë¸”ì„ ìœ„í•´ ì•¡ì…˜ ì €ìž¥
            obs, _, done, _, _ = env.step(action)
        
        all_histories[name] = env.asset_memory
        ensemble_actions.append(model_acts)
        
        ret = ((env.asset_memory[-1] / 10_000_000) - 1) * 100
        print(f"ðŸ’° {name.upper()} ìˆ˜ìµë¥ : {ret:.2f}% | ë§ˆì§€ë§‰ Action: {model_acts[-1]:.4f}")
    else:
        print(f"âŒ {name} ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

# 2. ì•™ìƒë¸” ê²°ê³¼ ê³„ì‚°
if ensemble_actions:
    avg_actions = np.mean(ensemble_actions, axis=0)
    env = Custom1MinEnv(df=test_df, **env_kwargs)
    obs, _ = env.reset()
    for act in avg_actions:
        obs, _, _, _, _ = env.step([act])
    all_histories['Ensemble'] = env.asset_memory
    print(f"ðŸš€ ì•™ìƒë¸” ìµœì¢… ìˆ˜ìµë¥ : {((env.asset_memory[-1]/10_000_000)-1)*100:.2f}%")

# 3. ê·¸ëž˜í”„ ê·¸ë¦¬ê¸°
plt.figure(figsize=(12, 7))
colors = {'ppo': 'blue', 'a2c': 'green', 'ddpg': 'orange', 'sac': 'red', 'Ensemble': 'black'}
styles = {'Ensemble': '--'}

for name, history in all_histories.items():
    plt.plot(history, label=name.upper(), color=colors.get(name, 'gray'), 
             linestyle=styles.get(name, '-'), linewidth=2 if name == 'Ensemble' else 1.5)

plt.title("Trading Strategy Comparison (Stock: 0120G0)")
plt.xlabel("Time (Minutes)")
plt.ylabel("Total Asset (KRW)")
plt.legend()
plt.grid(True, alpha=0.3)
plt.savefig(os.path.join(base_dir, "final_report_plot.png"))
print(f"ðŸ’¾ ë¹„êµ ë³´ê³ ì„œ ê·¸ëž˜í”„ ì €ìž¥ ì™„ë£Œ: final_report_plot.png")